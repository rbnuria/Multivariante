%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Plantilla básica de Latex en Español.
%
% Autor: Andrés Herrera Poyatos (https://github.com/andreshp) 
%
% Es una plantilla básica para redactar documentos. Utiliza el paquete fancyhdr para darle un
% estilo moderno pero serio.
%
% La plantilla se encuentra adaptada al español.
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%-----------------------------------------------------------------------------------------------------
%	INCLUSIÓN DE PAQUETES BÁSICOS
%-----------------------------------------------------------------------------------------------------

\documentclass{article}

\usepackage{lipsum}                     % Texto dummy. Quitar en el documento final.

%-----------------------------------------------------------------------------------------------------
%	SELECCIÓN DEL LENGUAJE
%-----------------------------------------------------------------------------------------------------

% Paquetes para adaptar Látex al Español:
\usepackage[spanish,es-noquoting, es-tabla, es-lcroman]{babel} % Cambia 
\usepackage[utf8]{inputenc}                                    % Permite los acentos.
\selectlanguage{spanish}                                       % Selecciono como lenguaje el Español.

%-----------------------------------------------------------------------------------------------------
%	SELECCIÓN DE LA FUENTE
%-----------------------------------------------------------------------------------------------------

% Fuente utilizada.
\usepackage{courier}                    % Fuente Courier.
\usepackage{microtype}                  % Mejora la letra final de cara al lector.

%-----------------------------------------------------------------------------------------------------
%	ESTILO DE PÁGINA
%-----------------------------------------------------------------------------------------------------

% Paquetes para el diseño de página:
\usepackage{fancyhdr}               % Utilizado para hacer títulos propios.
\usepackage{lastpage}               % Referencia a la última página. Utilizado para el pie de página.
\usepackage{extramarks}             % Marcas extras. Utilizado en pie de página y cabecera.
\usepackage[parfill]{parskip}       % Crea una nueva línea entre párrafos.
\usepackage{geometry}               % Asigna la "geometría" de las páginas.

% Se elige el estilo fancy y márgenes de 3 centímetros.
\pagestyle{fancy}
\geometry{left=3cm,right=3cm,top=3cm,bottom=3cm,headheight=1cm,headsep=0.5cm} % Márgenes y cabecera.
% Se limpia la cabecera y el pie de página para poder rehacerlos luego.
\fancyhf{}

% Espacios en el documento:
\linespread{1.1}                        % Espacio entre líneas.
\setlength\parindent{0pt}               % Selecciona la indentación para cada inicio de párrafo.

% Cabecera del documento. Se ajusta la línea de la cabecera.
\renewcommand\headrule{
	\begin{minipage}{1\textwidth}
		\hrule width \hsize 
	\end{minipage}
}

% Texto de la cabecera:
\lhead{}                          % Parte izquierda.
\chead{}                                    % Centro.
\rhead{\subject \ - \doctitle}              % Parte derecha.

% Pie de página del documento. Se ajusta la línea del pie de página.
\renewcommand\footrule{                                 
	\begin{minipage}{1\textwidth}
		\hrule width \hsize   
	\end{minipage}\par
}

\lfoot{}                                                 % Parte izquierda.
\cfoot{}                                                 % Centro.
\rfoot{Página\ \thepage\ de\ \protect\pageref{LastPage}} % Parte derecha.

%----------------------------------------------------------------------------------------
%	MATEMÁTICAS
%----------------------------------------------------------------------------------------

% Paquetes para matemáticas:                     
\usepackage{amsmath, amsthm, amssymb, amsfonts, amscd} % Teoremas, fuentes y símbolos.

% Nuevo estilo para definiciones
\newtheoremstyle{definition-style} % Nombre del estilo
{6pt}                % Espacio por encima
{6pt}                % Espacio por debajo
{}                   % Fuente del cuerpo
{}                   % Identación: vacío= sin identación, \parindent = identación del parráfo
{\bf}                % Fuente para la cabecera
{.}                  % Puntuación tras la cabecera
{.5em}               % Espacio tras la cabecera: { } = espacio usal entre palabras, \newline = nueva línea
{}                   % Especificación de la cabecera (si se deja vaía implica 'normal')

% Nuevo estilo para teoremas
\newtheoremstyle{theorem-style} % Nombre del estilo
{6pt}                % Espacio por encima
{0pt}                % Espacio por debajo
{\itshape}           % Fuente del cuerpo
{}                   % Identación: vacío= sin identación, \parindent = identación del parráfo
{\bf}                % Fuente para la cabecera
{.}                  % Puntuación tras la cabecera
{.5em}               % Espacio tras la cabecera: { } = espacio usal entre palabras, \newline = nueva línea
{}                   % Especificación de la cabecera (si se deja vaía implica 'normal')

% Nuevo estilo para ejemplos y ejercicios
\newtheoremstyle{example-style} % Nombre del estilo
{5pt}                % Espacio por encima
{0pt}                % Espacio por debajo
{}                   % Fuente del cuerpo
{}                   % Identación: vacío= sin identación, \parindent = identación del parráfo
{\scshape}                % Fuente para la cabecera
{:}                  % Puntuación tras la cabecera
{.5em}               % Espacio tras la cabecera: { } = espacio usal entre palabras, \newline = nueva línea
{}                   % Especificación de la cabecera (si se deja vaía implica 'normal')

% Teoremas:
\theoremstyle{theorem-style}  % Otras posibilidades: plain (por defecto), definition, remark
\newtheorem{theorem}{Teorema}[section]  % [section] indica que el contador se reinicia cada sección
\newtheorem{corollary}[theorem]{Corolario} % [theorem] indica que comparte el contador con theorem
\newtheorem{lemma}[theorem]{Lema}
\newtheorem{proposition}[theorem]{Proposición}

% Definiciones, notas, conjeturas
\theoremstyle{definition}
\newtheorem{definition}{Definición}[section]
\newtheorem{conjecture}{Conjetura}[section]
\newtheorem*{note}{Nota} % * indica que no tiene contador

% Ejemplos, ejercicios
\theoremstyle{example-style}
\newtheorem{example}{Ejemplo}[section]
\newtheorem{exercise}{Ejercicio}[section]

%-----------------------------------------------------------------------------------------------------
%	PORTADA
%-----------------------------------------------------------------------------------------------------

% Elija uno de los siguientes formatos.
% No olvide incluir los archivos .sty asociados en el directorio del documento.
\usepackage{title1}
%\usepackage{title2}
%\usepackage{title3}

%-----------------------------------------------------------------------------------------------------
%	TÍTULO, AUTOR Y OTROS DATOS DEL DOCUMENTO
%-----------------------------------------------------------------------------------------------------

% Título del documento.
\newcommand{\doctitle}{Clase esférica y elíptica  de distribuciones}
% Subtítulo.
\newcommand{\docsubtitle}{Trabajo A}
% Fecha.
\newcommand{\docdate}{20 \ de \ Diciembre \ de \ 2017}
% Asignatura.
\newcommand{\subject}{Estadística Multivariante}
% Autor.
\newcommand{\docauthor}{Antonio R. Moya Martín-Castaño \\Elena Romero Contreras \\Nuria Rodríguez Barroso}
\newcommand{\docaddress}{Universidad de Granada}
\newcommand{\docemail}{anmomar85@correo.ugr.es \\ elenaromeroc@correo.ugr.es \\ rbnuria6@gmail.com}

%-----------------------------------------------------------------------------------------------------
%	RESUMEN
%-------------------------------					----------------------------------------------------------------------

% Resumen del documento. Va en la portada.
% Puedes también dejarlo vacío, en cuyo caso no aparece en la portada.
%\newcommand{\docabstract}{}
\newcommand{\docabstract}{}

\begin{document}

 \maketitle

%-----------------------------------------------------------------------------------------------------
%	ÍNDICE
%-----------------------------------------------------------------------------------------------------

% Profundidad del Índice:
%\setcounter{tocdepth}{1}

\newpage
\tableofcontents
\newpage
	
%----------------------------------------------------------------------------------------
%	Sección 1: Deficiones y teoremas
%----------------------------------------------------------------------------------------

\section{Introducción.}

	La distribución normal multivariante que hemos desarrollado en clase de teoría, es un caso particular de una familia de distribuciones muy utilizadas en el análsis multivariante, las \textit{distribuciones elípticas}. Para introducirlas, consideraremos en primer lugar el caso más simple de estas, las \textit{distribuciones esféricas}.
	
	Para finalizar, veremos casos concretos de distribuciones de estas clases en $\mathbb{R}^p$.

\section{Clases esférica y elíptica de distribuciones en $\mathbb{R}^p$}
	
	\begin{definition}
		Dado un vector aleatorio \textbf{X} = $(X_1, ... , X_p)^t$, se dice que se distribuye en la clase esférica de distribuciones en $\mathbb{R}^p$ si \textbf{X} y \textbf{HX} tienen la misma distribución, $\forall$\textbf{H} $\in O(p)$ siendo $O(p)$ el grupo de matrices ortogonales de orden p. Esto es, si su distribución es invariante frente a transformaciones ortogonales. 
	\end{definition}

	

	\begin{example}
		Un ejemplo de densidad esférica es la distribución uniforme en la hiperesfera de radio r:
		
		\begin{center}
		\begin{math}
				f_x(\textbf{x}) = \frac{\Gamma(\frac{p+2}{2})}{\pi ^ {p/2} r^p} \textbf{I}_{[\textbf{x}^t\textbf{x} \leq r^2]}
		\end{math}
		\end{center}
	\end{example}


	Vemos ahora un resultado sobre la forma que adopta la función característica de cualquier variable que se distribuya en la clase esférica.
	
	\begin{theorem}
		Sea \textbf{X} un vector aleatorio con distribución en la clase esférica. Entonces su función característica es de la forma $\phi($\textbf{t}$) = \psi$(\textbf{t}$^t$\textbf{t}), con $\psi$ una cierta función. Además, E\textbf{[X] = 0} y Cov[\textbf{X}]  = $-2\psi'(0)$\textbf{I}$_p$.
	\end{theorem}

	\begin{proof}
		
		Para la primera parte de esta demostración vamos a utilizar resultados de la teoría de invarianzas:
		
		\begin{definition}
			Se dice que una función $\Phi$ es invariante sobre el espacio $\chi$ es invariante bajo G si verifica $\Phi(gx) = \Phi(x), \forall x \in \chi, \forall g \in G$
		\end{definition}
	
		\begin{definition}
			Una función $\Phi$ sobre $\chi$ se dice invariante maximal bajo G si es invariante bajo G y además verifica $\phi(x_1) = \phi(x_2) \Rightarrow x_1 \sim x_2 (mod G)$
		\end{definition}
	
		\begin{theorem}
			Sea $\Phi$ un invariante maximal bajo G para $\chi$. Entonces una función $\psi$ sobre $\chi$ es invariante bajo G sí y solo sí es función de $\Phi$.
		\end{theorem}
	
	\begin{proposition}
		Sea $G = O(p)$ el grupo  de matrices ortogonales de orden $p \times p$. Entonces $\Phi(x) = x^tx$ es un invariante maximal bajo G.
	\end{proposition}

	Para ver que $\Phi(t) = \psi(t^tt)$, basta con considerar la función $f(t) = t^tt$, que es un invariante maximal por la proposición anterior, y que $\Phi$ es un invariante por la definición de clase esférica (como $X$ y $HX$ tienen la misma distribución, $\Phi_x(t) = \Phi_x(Ht), \forall H \in G$). Entonces, aplicando el Teorema anterior, tenemos que $\Phi(t) = \psi(f(t)) = \psi(t^tt)$, para alguna función $\psi$.
	
	Para demostrar que $E[X] = 0$, basta con darse cuenta de que, dado que $X$ y $HX$  tienen la misma distribución, se verifica que $E[X] = E[HX], \forall H \in O(p)$,  y por la linealidad de la esperanza matemática sabemos que $E[HX] = H E[X], \forall H \in O(p)$, por tanto, llegamos a que $E[X] = HE[X], \forall H \in O(p)$, luego se debe verificar que $E[X] = 0$.
	
	Para demostrar la expresión de la covarianza, vamos a utilizar que $E[X^2] = - \Phi''(0)$. Por otro lado, calculamos la expresión de $\Phi''(t)$ en función de $\psi$, $\Phi''(t) = 2 \psi ' (t^tt)I_p + 4 t^2 \psi''(t^t t)I_p$, por tanto $\Phi''(0) = 2 \psi'(t^t t) I_p$.
	
	Finalmente, $Cov[X] = E[X^2] = - \Phi''(0) = - 2 \psi'(t^t t) I_p$, que es lo que buscábamos.
	
	\end{proof}

	\begin{definition}
		Dado un vector aleatorio \textbf{X} = $(X_1, ..., X_p)^t$, se dice que se distribuye en la clase elíptica de parámetros $\mu \in \mathbb{R}^p$ y \textbf{V}$_{p \times p}$ (\textbf{V} $> 0$) si su densidad es de la forma
		
		\begin{center}
		\begin{math}
			f(\textbf{x}) = C_p|\textbf{V}|^{-\frac{1}{2}}h((\textbf{x}-\mu)^t\textbf{V}^{-1}(\textbf{x}-\mu))
		\end{math}
		\end{center}
		donde $C_p$ es una constante y h una función suficientemente regular. A la clase elíptica la notaremos por $E_p(\mu; V)$.
	\end{definition}

	\begin{example}
		Un ejemplo de densidad elíptica es la distribución uniforme en el elipsoide de dimensión p:
		
		\begin{center}
			\begin{math}
				f_x(\textbf{x}) = \frac{\Gamma(\frac{p+2}{2}|\textbf{A}|^\frac{1}{2})}{\pi^\frac{p}{2}r^0}\textbf{I}_{[(\textbf{x}-\mu)^t\textbf{A}(\textbf{x}-\mu)\leq r^2]}
			\end{math}
		\end{center}

	\end{example}

	\textbf{EJERCICIOS:}
		\begin{itemize}
			\item Ejercicio 1: Comprobar que la clase esférica coincide con la elíptica $E(0; I_p )$.
			
			\textit{Solución:} 
			
			Si tenemos que un vector aleatorio \textbf{X} = $(X_1, ..., X_p)^t$ se distribuye en la clase elíptica $E(0; I_p )$, entonces cumple que su función de densidad es de la forma $f_x(\textbf{x}) = C_p h (x^tx)$, por lo que sólo depende de x a través de $x^tx$. De este modo, es invariantes por transformaciones ortogonales con lo que pertenece también a la clase esférica. ¿¿¿¿El OTRO CASO???
			
			\item Ejercicio 2: Verificar la siguiente caracterización, que generaliza la vista en el caso normal: $$ X \in E_p(\mu; V) \leftrightarrows X = \mu + CU $$ donde $\mu \in \mathbb{R}^p$ , C es la matriz dada por la descomposición de Cholesky de V, es decir, $V=CC^t$ y $U$ es un vector de la clase esférica p-dimensional.
			
			\textit{Solución:}
			
				Consideramos $X = \mu + CU $, y calculamos cual es su función de distribución. Para ello, como $U$ es un vector de la clase esférica p-dimensional, consideramos $f_U$ su función de distribución. Por lo que ya hemos demostrado, $f_U$ depende de $t$ solo a través de $t^tt$, esto es $_u(tf)=h(t^tt)$,para cierta función $h$. Además, estamos considerando que la matriz C es no singular. Por tanto, la transformación de U a X tiene el Jacobiano $J = det(C^{-1})$, y tenemos que aplicando un resultado de transformación para vectores aleatorios podemos obtener la función de densidad de $X$ como:
				
				\[
					f_x(x) = |det(C^{-1})| f_U |C^{-1}(x-\mu)| = [det(A)^{-1}det(A^{-1})]^{1/2}h[(x-\mu)^t(A^t)^{-1}A^{-1}(x-\mu)] =
				\]
								
				\[
									det[(AA^t)^{-1}]^{1/2}h[(x-\mu)^t(AA^t)^{-1}(x-\mu)] = \frac{h[(x-\mu)^tV^{-1}(x-\mu)]}{|V|^{1/2}}				
				\]
				
				
				
			\item Ejercicio 3: Verificar que si $X \in E_p(\mu; V)$  entonces $E[X] = \mu + CE[U]$ y $Cov(X)= C Cov(U)C^t$ siendo U pertenciente a la clase esférica.
			
			\textit{Solución:}
			
			Dada la linealidad de la esperanza matemática, sabemos que $E[\mu + CU] = E[\mu] + E[CU] = \mu + CE[U]$.
			
			En cuanto a la covarianza, dada la invarianza por translaciones obtenemos que $Cov[\mu + CU] = Cov[CU]$, y aplicando la bilinealidad de la covarianza obtenemos $Cov[CU] = C Cov[U]C^t$, por lo que hemos obtenido que $Cov[\mu + CU] = C Cov[U] C^t$.

		\end{itemize}
		
		En cuanto a la función característica, se plantea el siguiente ejercicio:
		
		\begin{itemize}
			\item Ejercicio 4: Sea \textbf{X} un vector aleatorio con distribución en la clase elíptica $E_p(\mu; V)$. Entonces su función característica es de la forma $\phi(u)=e^{iu^t\mu}\psi(u^tVu)$, con $\psi$ una cierta función.		
			
			\textit{Solución:}
			
			Sea $X \in E_p(\mu,V)$, aplicando al definición de función característica tenemos
			\[
				\phi_X(u) = \phi(u) = E[exp(iu^tX)] = E[exp(iu^t(\mu + CU))] = exp(i u^t \mu) \phi_{CU}(u) = exp(iu^t\mu)\phi_U(C^t u)
			\]
			
			Aplicando ahora el primer resultado que hemos demostrado ($\phi_u(t) = \psi(t^tt)$) para una cierta función $\chi$ tenemos
			
			\[
				\phi(u) = exp(iu^t\mu)\psi(t^tCC^tt) = exp(i u^t \mu) \psi(t^t V t)
			\]
			 
			 como buscábamos.
			
			\item Ejercicio 5: Sea \textbf{X} un vector aleatorio con distribución en la clase elíptica $E_p(\mu; V)$. Comprobar que si $A_{qxp}$ es una matriz de constantes con rg(A)=$q\leq p$, y c$\in\mathbb{R}^p$, entonces \textbf{Y = c + AX}$\in E_q(c+A\mu; AVA^t)$.
			
			\textit{Solución: }
			
			Volvemos a ver $X \in E_p(\mu; V)$ de la forma $X = \mu + CU$, donde $U$ pertenece a la clase esférica. Entonces:
			\[
				Y = c + AX = c + A(\mu + CU) = (c + A \mu) + (AC)U
			\]
			
			por tanto, obtenemos otra vez una elíptica de distribución $Y \in E_p(c + A \mu; (AC)(AC)^t) =  E_p(c + A \mu; AVA^t) $, como queríamos probar.
			
			
			\item Ejercicio 6: Sea \textbf{X}$\in E_p(\mu; V)$. Entonces $E[X]=\mu$ y $Cov[X]=-2\psi'(0)$V.
			
			\textit{Solución: }
			
			Para resolver este ejercicio, basta con utilizar el ejercicio anterior en el que se expresaba la esperanza matemática y la matriz de  correlaciones de un vector aleatorio con distribución elíptica $X = \mu + CU$ en función de la esperanza matemática y la matriz de correlaciones de $U$, siendo $U$ perteneciente a la clase esférica junto $E[U]$ y $Cov[U]$ calculadas anteriormente, de esta forma tenemos:
			\[
				E[X] = \mu + C E[U] = \mu + C 0 = \mu
			\]
			\[
				Cov[X] = C Cov[U] C^t = C (-2 \psi'(0)) I_p XC^t = -2 \psi'(0) C I_p C^t = -2 \psi'(0) V
			\]
			
			\item Ejercicio 7: Comprobar que todas las distribuciones de la clase elíptica $E_p(\mu; V)$ tienen igual matriz de correlaciones.
			
			\textit{Solución:}
			
			Recordamos la definición de la matriz de correlaciones de una distribución de la forma:
			
			\[
				cor_{i,j} = \frac{cov_{i,j}}{\sqrt{cov_{i,i}} \sqrt{cov_{j,j}}}
			\]
		
			Ahora bien, como $Cov[X] = -2 \psi'(0) V$, que solo depende de V que es común en todas las distribuciones de la clase elíptica $E_p(\mu; V)$.
			
			Por tanto, obtenemos que cada elemento de la matriz de correlaciones es el mismo en todas las distribuciones de la clase, luego la matriz de correlaciones es igual.
			
		\end{itemize}
		
		\textbf{EJERCICIO 8:}
		
		Sea \textbf{X}$\in E_p(\mu; V)$. Particionemos el vector \textbf{X} de la forma \textbf{X}=$(X^t_{(1)}|X^t_{(2)})^t$ donde $X_{(1)}$ es de dimensión $q$x1 y $X_{(2)}$ lo es $(p-q)$x1. Consideremos en $\mu$ y \textbf{V} las particiones inducidas
		$$\mu = \left( \begin{array}{c}
						\mu_{(1)} \\ \mu_{(2)}
						\end{array}\right);
		V = \left( \begin{array}{cc}
					V_{11} & V_{12} \\ V_{21} & V_{22}
					\end{array}\right)$$
		Entonces se verifica
		\begin{itemize}
			\item $X_{(1)} \in E_q(\mu_{(1)}; V_{11})$
			\item $X_{(2)} \in E_{(p-q)}(\mu_{(2)}; V_{22})$
		\end{itemize}
		
		\textbf{Nota}: Hacerlo usando la función característica y también mediante la caracterización obtenida en el primer ejercicio.
		
		\begin{proof}
			
			\textit{Demostración usando la función característica: } 
			
			Basta con aplicar la definición de función característica anteriormente considerada tomando $u = (u_1^t: 0^t)^t$, donde $u_1$ es de dimensión qx1. Así, tenemos que
			\[
				\phi_{X_1}(u_1) = exp(i u_1^t \mu_1^t) \psi(u_1^t V_{11} u_1)
			\]
			
			que es la función característica de un vector aleatorio con distribución elíptica $E_q(\mu_1, V_{11})$.
			
			De forma análoga, tomando $u = (0^t; u_2^t)$, donde $u_2$ es de dimensión (p-1)x1, otenemos
			\[
							\phi_{X_2}(u_2) = exp(i u_2^t \mu_2^t) \psi(u_2^t V_{2} u_2)
			\]
			
			
			\textit{Con la caracterización obtenida en el primer ejercicio}
			$rg(A) = q \leq p$ y $c \in R^p$.
			

		Vamos a demostrarlo hora utilizando que $Y = c + AX \in E_q(c + A \mu; A V A^t)$ , donde  $rg(A) = q \leq p$ y $c \in \mathbb{R}^p$.
		
		Para este caso, tenemos que $X_1 = A_1 X$, donde $A_1 = \left( \begin{array}{cc}
		I_q & 0 \\ 0 & 0
		\end{array}\right)$

	
	  donde $rg(A_1) = rg(I_q) = q$ y $c = 0$, por tanto, aplicando la caracterización anterior, tenemos que $X_1 \in E_q(A_1 \mu; A V A^t) = E_q(\mu_1, V_{11})$.
	  
	  
	  Análogamente, tenemos $X_2 = A_2 X$, donde $A_2 = \left( \begin{array}{cc}
	  0 & 0 \\ 0 & I_{(p-q)}
	  \end{array}\right)$
	  
	  Y en este caso, se verifica $rg(A_2) = p-q$ y $c = 0$, luego tenemos $X_2 \in E_{(p-q)}(A_2 \mu, A V A^t) = E_{(p-q)}(\mu_2, V_{22})$
	
	\end{proof}
	\section{Algunas distribuciones de las clases esférica y elíptica de distribuciones en $\mathbb{R}^p$ }
	
	\subsection{Distribución uniforme en el círculo de radio r}
	
	Sea $S=\{(x_1, x_2) \in \mathbb{R}^2: x_1^2+x_2^2 \leq r^2\}$ el círculo centrado en el origen y de radio $r>0$. Dado un vector aleatorio: \textbf{X} = $(X_1, X_2)^t$ se dice que sigue la distribución uniforme en $S^1$ si su densidad es $$f(x_1,x_2) = KI_{S^1}$$ donde $K>0$ e $I_{S^1}$ es la función indicadora en $S^1$.
	
	\textbf{EJERCICIOS:}
	
	\begin{itemize}
		\item Ejercicio 9: Verificar que $K=\frac{1}{\pi r^2}$
		
		\textit{Solución:} Tengamos en cuenta que $\int_{-\infty}^{\infty} f_X(X) dX = 1$. Por tanto $K \int_{-\infty}^{\infty} I_{S^1} dX =1 $. Así: $$K \int_{S^1}^{}1dX = 1 $$ Y por tanto, atendiendo a que esa integral coincide con el área de un círculo: $K\pi r^2 = 1$. Y como conclusión sacamos que $K=\frac{1}{\pi r^2}$
		
		\item Ejercicio 10: Comprobar que $E[X]=0$ y que $Cov[X] = \frac{r^2}{4}I_2$
		
		\textit{Solución:}
		$$E[X]=\int_{-\infty}^{+\infty}xf(x) dx = \int_{-\infty}^{+\infty}xKI_{S^1} dx = \int_{S^1}Kx dx = k \cdot \int_{S^1}x dx$$ 
		
		Realizamos cambio a polares:
		 $$x_1 = \rho cos(\theta), x_2 = \rho sen(\theta)$$
		donde $\rho>0$ y $0<\theta\leq2\pi$
		
		Definimos $\phi:]0,r[\times]0,2\pi[\longrightarrow S^1$ difeomorfismo con $\phi(\rho,\theta) = (\rho cos(\theta), \rho sen(\theta))$
		
		Calculamos el jacobiano:
		
		$$|Jac \phi|(\rho,\theta) = \left| \begin{array}{cc}
		cos(\theta) & -\rho sen(\theta) \\
		sen(\theta) & \rho cos(\theta)  \end{array} \right| = |\rho(cos^2(\theta)+sen^2(\theta))| = |\rho| = \rho$$
		
		$$\int_{S^1}f(x_1,x_2) dx = \int_{0}^{r}\int_{0}^{2\pi}x(f\circ \rho)(\rho,\theta)|Jac \phi|(\rho,\theta)d\theta d\rho = \int_{0}^{r}\int_{0}^{2\pi}(\rho^2cos(\theta),\rho^2sen(\theta))d\theta d\rho$$
		$$ \int_{0}^{r}\rho^2\left[(sen(\theta),-cos(\theta)\right]_0^{2\pi} d\rho = \int_0^{r^2}\rho^2\left[(0,1)-(0,-1)\right]d\rho = \int_0^{r^2}0d\rho = 0$$		
		
		Luego $E[X]=0$
		
		Veamos ahora que $Cov[X] = \frac{r^2}{4}I_2$. En primer lugar, comprobemos que $Var[X]=\left(\frac{r^2}{4},\frac{r^2}{4}\right)$
		
		$$\int_{-\infty}^{+\infty}x^2f(x_1,x_2)dx = \int_{-\infty}^{+\infty}x^2\cdot kI_{S^1}dx = k\int_{S^1}x^2dx$$
		Realizamos el cambio a polares anterior:
		$$k\cdot \int_{S^1}x^2dx = k \int_{0}^{r}\left(\int_{0}^{2\pi}(\rho^3cos^2(\theta),\rho^3sen^2(\theta))d\theta)d\rho\right) = k \int_{0}^{r}\rho^3\left(\int_0^{2\pi}(cos^2(\theta),sen^2(\theta)d\theta\right)d\rho$$
		$$=k \int_{0}^{r}\rho^3\left[\frac{1}{2}\left(\theta+sen(\theta)cos(\theta),\theta-sen(\theta)cos(\theta)\right)\right]^{2\pi}_{0} =k\int_{0}^{r}\rho^3(\pi,\pi)d\rho = (\pi,\pi)\int_{0}^{r}\rho^3 d\rho$$
		$$=k(\pi,\pi)\left[\frac{\rho^4}{4}\right]^r_0 = =k(\pi,\pi)\frac{r^4}{4}$$
		
		Usando que $k=\displaystyle\frac{1}{\pi r^2}$ tenemos que 
		
		$$Var[X]=\left(\frac{r^2}{4},\frac{r^2}{4}\right)$$
		
		Calculamos ahora $Cov[X_1,X_2]$ que coincide con $Cov[X_2,X_1]$:
		
		$$Cov[X_1,X_2] = k \int_{S^1}x_1\cdot x_2\; dex = k \int_{0}^{r}\int_{0}^{2\pi}\rho^3cos(\theta)sen(\theta)\;d\theta d\rho = k \int_{0}^{r}\frac{\rho^3}{2}\left(\int_{0}^{2\pi}sen(2\theta)\;d\theta\right)d\rho$$
		$$=k\int_{0}^{r}\frac{\rho^3}{4}\left[cos(2\theta)\right]_0^{2\pi}\;d\rho=k\int_{0}^{r}0\;d\rho = 0$$
		
		Luego
		
		$$Cov[X] = \left( \begin{array}{cc}
		Var[X_1] & Cov[X_1,X_2]\\
		Cov[X_1,X_2] & Var[X_2]
		\end{array}\right) =
		\left( \begin{array}{cc}
		\frac{r^2}{4} & 0\\
		0 & \frac{r^2}{4}
		\end{array}\right) = \frac{r^2}{4}I_2$$
		
		
		\item Ejercicio 11: Calcular las distribuciones marginales así como las condicionadas. Por simetría basta calcular la distribución de $X_1$  y la de $X_1|X_2=x2$. 
		\textit{Solución:}
		
		$$f_{X_1}(x_1)=\int f(x_1,x_2)\; dX2$$
		
		Calculamos rango de $X_2$:
		
		$$x_1^2+x_2^2 \leq r^2 \Rightarrow x_2^2 \leq r^2 - x_1^2 \Rightarrow -\sqrt{r^2-x_1^2}\leq x_2 \leq\sqrt{r^2-x_1^2}$$
		
		Entonces:
		
		$$f_{X_1}(x_1) = \int_{-\sqrt{r^2-x_1^2}}^{\sqrt{r^2-x_1^2}}f(x_1,x_2) \; dX_2 = \int_{-\sqrt{r^2-x_1^2}}^{\sqrt{r^2-x_1^2}}k \; dX_2 = k\cdot \displaystyle\left.X_2\right]_{-\sqrt{r^2-x_1^2}}^{\sqrt{r^2-x_1^2}}$$
		$$=2k\sqrt{r^2-x_1^2} = \frac{2\;\sqrt{r^2-x_1^2}}{\pi r^2};\;\;-r\leq x_1\leq r$$
		
		Para calcular la condicionada usamos:
		
		$$f(X_1,X_2) = f(X_2)f(X_1|X_2)\Rightarrow f(X_1|X_2=x_2) = \frac{f(X_1,X_2)}{f(X_2)} = \frac{k\;I_{S^1}}{2k\sqrt{r^2-x_2^2}}$$
		
		Como $-r\leq x_2\leq$ y $x_1^2\leq r^2-x_2^2$ para que $I_{S^1}=1$,
		
		$$f(X_1,X_2)= \frac{k}{2k\sqrt{r^2-x_2^2}} = \frac{1}{2\sqrt{r^2-x_2^2}}$$
		
		
		 
	\end{itemize} 
	
	
	\subsection{Distribución uniforme en la esfera de radio r}
	
	Sea $S^2=\{(x_1, x_2, x_3) \in  \mathbb{R}^3: x_1^2 + x_2^2+x_3^2\leq r^2\}$ el interior y borde de la esfera centrada en 0 y de radio $r>0$. Dado un vector aleatorio \textbf{X} = $(X_1, X_2, X_3)^t$ se dice que sigue la distribución uniforme en $S^2$ si su densidad es:
	$$ f(x_1, x_2, x_3)= KI_{S^2}$$
	
	donde $K>0$ e $I_{S^2}$ en la función indicadora en $S^2$. 
	
	\textbf{EJERCICIOS:}
	\begin{itemize}
		\item Ejercicio 12: Verificar que $K=\frac{3}{4\pi r^3}$
		
		\textit{Solución:} De manera similar al caso del círculo, ahora tenemos que se cumple que $\int_{-\infty}^{\infty} f_X(X) dX = 1$. Por tanto $K \int_{-\infty}^{\infty} I_{S^2} dX =1 $. Así: $$K \int_{S^2}^{}1dX = 1 $$ Y por tanto, atendiendo a que esa integral coincide con el área de una esfera: $K\frac{4}{3}\pi r^3 = 1$. Y como conclusión sacamos que $K=\frac{3}{4\pi r^3}$
		
		\item Ejercicio 13: Comprobar que $E[X]=0$ y que $Cov[X] = \frac{r^2}{5}I_3$
		
		\textit{Solución:}
		
		
		Calculamos la matriz jacobiana del cambio a polares:
		
		\begin{equation}
		\left\{ 
		\begin{array}{l}
		x_1 = \rho cos(\theta) \\
		x_2 = \rho sen(\theta)cos(\phi) \\
		x_3 = \rho sen(\theta)sen(\phi)
		\end{array}
		\right.
		\end{equation}
		
		Entonces, $|Jac(\rho,\theta,\phi)| = \rho^2sen(\theta)$
		
		Calculamos dónde se mueve $\rho$:
		
		$$x_1^2+x_2^2+x_3^2 \leq r \Longleftrightarrow \rho^2cos^2(\theta)+\rho^2sen^2(\theta)cos^2(\phi)+\rho^2sen^2(\theta)sen^2(\phi) \leq r^2$$
		$$\Longleftrightarrow \rho^2cos^2(\theta)+\rho^2sen^2(\theta)[cos^2(\phi)+sen^2(\phi)] \leq r^2 \Longleftrightarrow \rho^2[cos^2(\theta)+sen^2(\theta)] \leq r^2 \Longleftrightarrow$$
		$$ \rho^2 \leq r^2 \Longleftrightarrow -r \leq \rho \leq r \text{ , pero } \rho>0$$
		
		Luego $0<\rho\leq r$
		
		$$E[X] = \int_{-\infty}^{+\infty}Xf(X) \; dX = \int_{-\infty}^{+\infty}(X_1,X_2,X_3)\cdot k I_{S^2} \; dX = k \cdot \int_{S^2}(X_1,X_2,X_3)\; dX$$
		
		Aplicamos ahora el cambio a polares:
		
		$$k \cdot \int_{S^2}(X_1,X_2,X_3)\; dX = k \cdot \int_{0}^{r} \int_{0}^{\pi} \int_{0}^{2\pi} (\rho cos(\theta), \rho sen(\theta)cos(\phi),
		\rho sen(\theta)sen(\phi)) \rho^2sen(\theta)\;d\phi\;d\theta\;d\rho$$
		$$= k \cdot \int_{0}^{r} \rho^3 \int_{0}^{\pi} sen(\theta) \int_{0}^{2\pi} (cos(\theta), sen(\theta)cos(\phi),sen(\theta)sen(\phi))\;d\phi\;d\theta\;d\rho$$
		
		$$= k \cdot \int_{0}^{r} \rho^3 \int_{0}^{\pi} sen(\theta) \left[(cos(\theta)\cdot \phi, sen(\theta)sen(\phi),-sen(\theta)cos(\phi))\right]^{2\pi}_0\;d\theta\;d\rho$$
		$$= 2\pi k \int_{0}^{r} \rho^3 \int_{0}^{\pi} (sen(\theta)cos(\theta),0,0)\;d\theta\;d\rho = 2\pi k \int_{0}^{r} \rho^3 \left[\left(\frac{-1}{2}cos^2(\theta),0,0\right)\right]_0^\pi$$
		$$= 2\pi k \int_{0}^{r} \rho^3 \left(\frac{-1}{2}+\frac{1}{2},0,0\right) = (0,0,0)$$
		
		
		\item Ejercicio 14: Calcular las distribuciones marginales unidimensionales y bidimensionales. Dada la simetría, basta con calcular la distribución de $X_1$ y de $(X_1, X_2)^t$
		
		\textit{Solución:}
	
		
		En primer lugar, calculamos \[f_{X_1, X_2}(x_1, x_2) = \int f(x_1, x_2, x_3) dX_3\] Calculamos el rango donde se mueve $X_3$: $x_1^2 + x_2 ^2 + x_3 ^2 \leq r^2 \rightarrow - \sqrt{r^2 - x_1^2 - x_2^2} \leq x_3 \leq \sqrt{r^2 - x_1^2 - x_2^2}$.
		
		Por tanto, \[f_{X_1, X_2}(x_1, x_2) = \int_{-\sqrt{r^2-x_1^2-x_2^2}}^{\sqrt{r^2 - x_1^2 - x_2^2}} k dX_3 = 2 k \sqrt{r^2 - x_1^2 - x_2^2} = \frac{3 \sqrt{r^2 - x_1^2 - x_2^2}}{2 \pi r^3}\]
		
		Para que la función de distribución esté bien definida, se tiene que verificar que $x_1 ^2 + x_2^2 \leq r^2$. 
		

		De la misma manera, calculamos \[f_{X_1}(x_1) = \int f_{X_1, X_2} dX_2\]. Calculamos el rango donde se mueve $X_2: x_1^2 + x_2^2 \leq r^2 \rightarrow - \sqrt{r^2 - x_1^2} \leq x_2 \leq  \sqrt{r^2 - x_1^2}$.
		
		Por tanto,
		
		\[
		f_{X_1}(x_1) = \frac{3}{2 \pi r^3} \int_{- \sqrt{r^2 - x_1^2} }^{\sqrt{r^2 - x_1^2}} f_{X_1, X_2} dX_2 =
		\]
		
		\[  = \frac{3}{2 \pi r^3} \left[\frac{1}{2} \left( x_2 \sqrt{ r^2 - x_1^2 - x_2 ^2 } + (r^2 - x_1 ^2) tan ^{-1} \left( \frac{x_2}{\sqrt{r^2 - x_1 ^2 - x_2^2}}\right)   \right) \right]_{- \sqrt{r^2 - x_1^2} } ^{\sqrt{r^2 - x_1^2}} =
		\]
		
		\[
		=\frac{3}{2 \pi r^3} \frac{1}{2} \pi (r^2 - x_1^2) =  \frac{3 (r^2 - x_1^2)}{4 r^3}
		\] 
		
		Para que esté bien definida, $-r \leq x_1 \leq r$.
		
		Por tanto, hemos obtenido que ambas distribuciones marginales se corresponden con la distribución uniforme del círculo y en un intervalo. 
		
		\item Ejercicio 15:  Calcular las distribuciones de $(X_2, X_3)^t|X_1=x_1$ y $X_3|X_1=x_1, X_2=x_2$. Deducir que son distribuciones uniformes en un círculo y en un intervalo, respectivamente y, en consecuencia, calcular los dos primeros momentos.
		
		\textit{Solución: }
		
		Para este ejercicio, vamos a utilizar que $f(x_1, x_2, x_3) = f_{X_1}(x_1) f(X_2, X_3 | X_1 = x_1) = f_{X_1 , X_2}(x_1, x_2) f(X_3 | X_1 = x_1, X_2 = x_2) $
		
		Así, 
		
		\[
			f_{X_2, X_3| X_2 = x_2, X_3 = x_3}(x_2, x_3) =  \frac{f(x_1,x_2,x_3)} {f_{X_1} (x_1)} = \frac{k}{ \frac{3 (r^2 - x_1^2)}{4 r^3} } = \frac{4 r^3}{3 k (r^2 - x_1^2)} = \frac{1}{\pi (r^2 - x^2)} 
		\]
		
		de la marginal heredamos la condición de $-r \leq x_1 \leq r$.
		
		De forma análoga,
		
		\[
			f_{ X_3| X_1 = x_1, X_2 = x_2}(x_3) = \frac{f(x_1, x_2, x_3)}{f_{X_1, X_2}}  = \frac{k}{\frac{3 \sqrt{r^2 - x_1^2 - x_2^2}}{2 \pi r^3}} = \frac{1}{ 2 \sqrt{r^2 - x_1^2 - x_2^2}}
		\] 
		
		de la marginal heredamos la condición de $x_3 ^ 2 \leq r^2 - x_1^2 - x_2^2$.
		
		Por los conjuntos en los que están definidas y porque no dependen del punto en el que evaluemos (son constantes), podemos deducir que:
		
		\begin{itemize}
			\item La distribución $Y = X_1|X_2 = x_2, X_3 = x_3$ se corresponde con una distribución uniforme en el intervalo $[-r,r]$.
			
			\item La distribución $Z =X_1, X_2|X_3 = x_3$ se corresponde con una distribución uniforme en el intervalo  en la esfera $x_1^2 + x_2^2 \leq r^2$.
		\end{itemize}
	
		Por tanto, para calcular los momentos de primer y segundo orden tenemos:
		\begin{itemize}
			\item Utilizando la esperanza y la varianza de una distribución uniforme en un intervalo tenemos $E[Y] = \frac{r -r}{2} = 0$ y $E[Y^2] = Var[Y] = \frac{(r+r)^2}{12} = \frac{r^2}{3}$
			\item Utilizando los ejercicios anteriores tenemos $E[Z] = (0,0)^t$ y $E[Z^2] = Var[Z] = \frac{r^2}{4}I_2$ 
		\end{itemize}
		
	\end{itemize}
	
	\subsection{Distribución uniforme en la hiperesfera de radio r}
	
	Sea $S^{p-1} = \{x \in \mathbb{R}^p: x^tx\leq r^2\}$ el interior y el borde de la hiperesfera centrada en el origen y de radio $r>0$. Dado un vector aleatorio \textbf{X} = $(X_1, \dots , X_p)^t$ se dice que sigue la distribución uniforme en $S^{p-1}$ si su densidad es:
	
	$$f(x_1, \dots, x_p)= KI_{S^{p-1}}$$
	
	donde $K>0$ e $I_{S^{p-1}}$ es la función indicadora en $ S^{p-1}$
	
	\textbf{EJERCICIOS:}
	\begin{itemize}
		\item Ejercicio 16: Verificar que $K = \frac{\Gamma(\frac{p+2}{2})}{\pi ^ {p/2} r^p}$.
		
		\textit{Solución:} 
		
		Sabemos que 
		\[
			 1 = \int f(x_1, ..., x_p) dX
		\]
		
		Calculamos ahora la integral,
		
		\[
			\int f(x_1, ..., x_p) dX = \int K I_{S^{p-1}} dX = \int_{S^{p-1}} k dX =
		\]
		
		aplicando cambio a polares 
		
		\[
			= 2 \pi k \int_0^p \rho^{p-1} \int_0^{\pi} \sin^{p-2}(\theta_1) d \theta_1 ... \int_0^{\pi} \sin(\theta_{p-e}) d \theta_{p-2}
		\]
		
		Para resolver esta integral vamos a utilizar que:
		\[
			\int_0^{\pi } \sin^k(\theta ) d\theta  = \frac{\Gamma(\frac{k+1}{2} )\sqrt{\pi} }{\Gamma(\frac{k+2}{2})}
		\]
		
		Por tanto, 
		
		\[
			\int_0^{\pi} \sin{p-2} \theta_1 d\theta_1 \int_0^{\pi} ... \int_{0}^{\pi} \sin\theta_{p-2} d\theta_{p-2} = 
			\prod_{i = 1}^{p-2} \frac{\Gamma(\frac{p-1}{2}) \sqrt{\pi}}{\Gamma(\frac{p-i+1}{2})} = \frac{\pi^{\frac{p-2}{2}}}{\Gamma(\frac{p}{2})}
		\]
		
		Finalmente,
		
		\[
			1 = \frac{k 2 \pi \pi^{\frac{p-2}{2}} r^p}{\Gamma(\frac{p}{2}) p} = \frac{k \pi^{\frac{p}{2}} r^p}{\Gamma(\frac{p}{2}) \frac{p}{2}} = \frac{k \pi^{\frac{p}{2}} r^p}{\Gamma(\frac{p}{2} +1)} \Rightarrow 
			k = \frac{\Gamma(\frac{p+2}{2})}{\pi^{\frac{p}{2}} r^p }
		\]
		
		
		\item Ejercicio 17: Comprobar que $E[X]=0$ y $Cov[X]=\frac{r^2}{p+2}I_p$.
		
		\textit{Solución:} 
		
		Para calcular $E[X]$ tenemos 
		\[
			E[X] = \int_{S^{p-1}} X f(x_1, ..., x_p) dx 
		\]
		
		Para ver que es 0, veamos componente a componente:
		\begin{itemize}
			\item Para las primeras $p-2$ componentes, tendríamos que tras cambiar a polares, tendríamos que la integral más interna es una integral del tipo 
			\[
				\int_0^{\pi} \sin^k \theta \cos \theta d\theta = 0
			\]
			
			\item En cuanto a la componente $p-1$, de igual forma tras cambiar a polares obtendríamos que la integral más interna sería
			\[
				\int_{0}^{\pi} \cos(\theta_{p-1}) d\theta_{p-1} = 0
			\]
			
			\item Análogamente para la componente $p$ tenemos que la integral más interna sería
			\[
				\int_{0}^{\pi} \sin(\theta_{p-1}) d\theta_{p-1} = 0			
			\]
			
		\end{itemize}
	
		Así, hemos obtenido que cada componente de la $E[X]$ es 0, luego $E[X] = 0$.
		
		Para calcular la Cov[X], vamos a calcular en primer lugar las varianzas de cada una de las variables.
		
		\begin{itemize}
			\item Para cada $k= 1, ..., p-2$ expresamos
			\[
				Var[X_k^2] = \int X_k^2 dX 
			\]
			
			y cambiando a polares tenemos
			
			\[
				Var[X_k^2] = k \int_0^r \rho^{p+1} \int_0^{\pi} \prod_{j = 1}^{p-3-r} (\sin \theta_j)^{p-j+1} \prod_{j = p-r-2}^{p-2}((\sin \theta_j)^{p-j-1}) \cos(\theta_k) d\theta_1 ... d\theta_{p-2} \int_o^{2 \pi} d\theta_{p-1} d\rho= 
			\]
			
			\[
			 = k 2\pi \int_0^r \rho^{p+1} \int_0^{\pi} \prod_{j = 1}^{p-3-r} (\sin \theta_j)^{p-j+1} \prod_{j = p-r-1}^{p-2}((\sin \theta_j)^{p-j-1})  \sin^{r+1}\theta_k\cos(\theta_k)  d\theta_1 ... d\theta_{p-2} d\rho = 
			 \]
			 
			 \[	
			 	  = k 2\pi \int_0^r \rho^{p+1}\int \prod_{j = 1}^{p-3-r} (\sin \theta_j)^{p-j+1} \prod_{j = p-r-1}^{p-2}((\sin \theta_j)^{p-j-1})  \int  \sin^{r+1}\theta_k\cos(\theta_k) d\theta_1 ... d\theta_{p-2} d\rho
			\]
			
			\[
				= k 2\pi \frac{\Gamma(\frac{r+2}{2}) \sqrt{\pi} k }{ \Gamma(\frac{r+5}{2})}  \int_0^r \rho^{p+1}  \int \prod_{j = 1}^{p-3-r} (\sin \theta_j)^{p-j+1} \int \prod_{j = p-r-1}^{p-2}(\sin \theta_j)^{p-j-1} \theta_1 ... d\theta_{p-2} d\rho=
			\]
			
			\[
				 = k 2\pi \frac{\Gamma(\frac{r+2}{2}) \sqrt{\pi} k }{ \Gamma(\frac{r+5}{2})}  \int_0^r \rho^{p+1} \int (\prod_{j = 1}^{p-3-r} (\sin \theta_j)^{p-j+1})  \prod_{j = p-r-1}^{p-2} \int (\sin \theta_j)^{p-j-1} \theta_1 ... d\theta_{p-2} d\rho= 
			\]
			
			\[
			 = 2 k \pi \frac{\Gamma(\frac{r+2}{2}) \sqrt{\pi} k }{ \Gamma(\frac{r+5}{2})}  \frac{\Gamma(1) (\sqrt{\pi})^{r-1}}{\Gamma(\frac{r+2}{2})}  \int_0^r \rho^{p+1}  \int (\prod_{j = 1}^{p-3-r} (\sin \theta_j)^{p-j+1})  \theta_1 ... d\theta_{p-2} d\rho = 
			 \]
			 
			 \[
			= 2 k \pi \frac{\sqrt{\pi}^r}{2 \Gamma(\frac{r+5}{2})} \int_0^r \rho^{p+1}  \int (\prod_{j = 1}^{p-3-r} (\sin \theta_j)^{p-j+1})  \theta_1 ... d\theta_{p-2} d\rho =
			\]
			
			\[
			 = k \pi \frac{\sqrt{\pi}^r}{\Gamma(\frac{r+5}{2})} \int_0^r \rho^{p+1}  \prod_{j = 1}^{p-3-r}  \int \sin \theta_j)^{p-j+1}  \theta_1 ... d\theta_{p-2} d\rho  = 
			 \]
			 
			 \[
			  = \frac{ k \pi \sqrt{\pi}^r}{\Gamma(\frac{r+5}{2})} \frac{\Gamma(\frac{r+5}{2}) \sqrt{\pi}^{p-2-r}}{\Gamma(\frac{p+2}{2})} \int_0^r \rho^{p+1}  d\rho = \frac{\pi k \pi^{\frac{p-2}{2}}}{\Gamma(\frac{p+2}{2})} \int_0^r \rho^{p+1} d\rho = \frac{\pi k r ^{p+2} \pi^{\frac{p-2}{2}}}{ \Gamma(\frac{p+2}{2})} \int_0^r \rho^{p+1} d\rho = 
			\]
			
			\[
			 =  \frac{\pi k r ^{p+2} \pi^{\frac{p-2}{2}}}{ \Gamma(\frac{p+2}{2})(p+2)} = \frac{r^2}{p+2}
			\]
			
			\item Veamos ahora las componentes $x_{p-1}, x_p$. Para empezar, tengamos en cuenta que 
			
			\[
				\int_{0}^{2 \pi} \sin^2(\theta) = \int_{0}^{2 \pi} \cos^2(\theta) = \pi
			\]

			Por tanto, para el caso $x_{p-1}$ y $x_p$, la integral que tenemos que resolver es:
			
			\[
				\pi k \int_{0}^{r} \rho^{p+1} d\rho \prod_{j = 1}^{p-2} \int_{0}^{\pi} \sin^{p-j+1}(\theta_j) d\theta_j =  \pi k \frac{\sqrt{\pi}^{p-2}}{\Gamma(\frac{p+2}{2})} \int_{0}^{r} \rho^{p+1} d\rho = \frac{r^2}{p+2}
			\]
					
		\end{itemize}
	
		Para concluir que $Cov[X] = \frac{r^2}{p+2}I_p$ queda comprobar que $Cov[X_i, X_j] = 0, \forall i \ne j$. Para $1 \leq i,j \leq p$ con $i \ne p-1$ y $j \ne p-1$ aparecen integrales del tipo
		
		\[
			\int_{0}^{\pi} \sin^k(\theta) \cos(\theta)d\theta = 0
		\]
		
		En caso de que $j = p-1$ y $i \ne p$ aparece la integral 
		
		\[
			\int_{o}^{2 \pi} cos(\theta_{p-1}) d\theta_{p-1} = 0
		\]
		
		Para finalizar, en el caso $i = p-1$ y $j = p$ aparece la integral
		
		\[
			\int_{0}^{2 \pi} \cos(\theta{p-1}) \sin(\theta_{p-1}) d\theta_{p-1} = 0
 		\] 
		
		\item Ejercicio 18: Calcular las distribuciones marginales unidimensionales y bidimensionales. Dada la simetría basta con calcular, por ejemplo, las de $X_1$ y $(X_1,X_2)^t$.
		
		\textit{Solución:}
		
		Para calcular la distribución marginal de $X_1$, integrando con respecto al resto de variables. Para esto, veamos dónde se mueven el resto de variables: $x_1^2 + x_2^2 + ... + x_p^2 \leq r^2 \Rightarrow  x_2^2 + ... + x_p^2  \leq r^2 - x_1^2$, espacio que se corresponde con una hiperesfera de una dimensión menos. Entonces:
		
		\[
			f_{X_1}(x_1) = k \int_{S^{p-2}} dx_2 ... dx_p 
		\]
		
		Notamos que estamos integrando el área de la superficie de $S^{p-2}$ de radio $\sqrt{r^2 - x_1^2}$, luego, utilizando el área de la hiperesfera: 
		
		\[
				f_{X_1}(x_1) = k \frac{\pi ^{\frac{p-1}{2}}  (\sqrt{r^2 - x_1^2})^{p-1}}{\Gamma(\frac{p-1}{2} + 1)} = \frac{\Gamma(\frac{p+2}{2})}{\sqrt{\pi} r^p \Gamma(\frac{p+1}{2})} (r^2 - x_1^2)^{\frac{p-1}{2}}
		\]
		
		donde $-r \leq x_1 \leq r$.
		
		
		Para la distribución bidimensional utilizamos un proceso análogo. Para calcular el rango en el que se mueven el resto de variables tenemos que: $x_1^2 + x_2^2 + ... + x_p^2 \leq r^2 \Rightarrow  x_3^2 + ... + x_p^2  \leq r^2 - x_1^2 - x_2^2$, espacio que se corresponde con una hiperesfera de dos dimensiones menos. Entonces:
		
		\[
			f_{X_1, X_2}(x_1, x_2) = k \int_{S^{p-3}} dx_3 ... dx_p
		\]
		
		que se correspondería con el volumen de la hiperesfera $S^{p-3}$ de radio $\sqrt{r^2 - x_1^2 - x_2^2}$. Por tanto, de manera análoga:
		
		\[
				f_{X_1, X_2}(x_1, x_2) = k \int_{S^{p-3}} dx_3 ... dx_p = \frac{\Gamma(\frac{p+2}{2})}{\pi^{p+2} r^p} \frac{\pi^{\frac{p+2}{2}}  (\sqrt{r^2 - x_1^2 - x_2 ^2})^{p-2} }{ \Gamma(\frac{p-2}{2} + 1)} = \frac{\Gamma(\frac{p+2}{2})}{\pi r^p \Gamma(\frac{p}{2})} (r^2 - x_1^2 - x_2 ^ 2) ^{\frac{p-2}{2}}
		\]
		
		donde $x_1^2 + x_2^2 \leq r^2$.
		
		\item Ejercicio 19: Si consideramos \textbf{X} partido en la forma \textbf{X}=$(X^t_{(1)}|X^t_{(2)})^t$ donde $X_{(1)}$ es de dimensión $q$ y $X_{(2)}$ lo es $(p-q)$, calcular la distribución de $X_{(1)}$.
		
		\textit{Solución: }
		
		Por inducción a partir de las dos marginales realizadas en el apartado anterior, nos damos cuenta que tienen la misma forma pero aumentando el exponente de $\pi$ de la forma $\pi^{\frac{dim}{2}}$, además la segunda parte es de la forma $(r^2 - x_1^2 - ... - x_{dim}^2)^{\frac{p-dim}{2}}$ y la gamma del nominador se ve afectada de la forma $\Gamma(\frac{p-dim+2}{2})$. De esta forma, podemos deducir que
		
		\[
			f_{X_{(1)}}(x_{(1)}) = \frac{\Gamma(\frac{p+2}{2})}{\pi^{\frac{q}{2}} r^p \Gamma(\frac{p-q+2}{2})} (r^2 -x_{(1)}^t x_{(1)}) ^{\frac{p-q}{2}}
		\] 
		
		donde $x_{(2)}^t x_{(2)} \leq r^2$.
		
		
		
		\item Ejercicio 20: Calcular la distribución condicionada $X_{(2)}|X_{(1)} = x_{(1)}$. Deducir que es una distribución uniforme en $S^{p-q-1}$, o sea, la esfera de dimensión $p-q$. En consecuencia, calcular los dos primeros momentos.
	\end{itemize}
	
	\subsection{Distribución T-Student esférica}
	
	Sea \textbf{X} = $(X_1, \dots , X_p)^t$ un vector aleatorio. Diremos que se distribuye según la distribución t de student esférica p-dimensional con n grados de libertad si su función de densidad es:
	$$ f(x_1, \dots, x_p)^t = \frac{\Gamma(\frac{n+p}{2})}{\Gamma(\frac{n}{2})(n \pi )^{\frac{p}{2}}[1+\frac{1}{n}x^tx]^{\frac{n+p}{2}}} $$ con $x \in \mathbb{R}^p$
	
	\textbf{EJERCICIO 21:} Demostrar que los momentos de esta distribución son:
	
	\textit{Solución: }
	
	$$ E[X]=0$$ $$ Cov[X]= \frac{n}{n-2}I_{p}$$ con $n>2$. 
	
	Vamos a demostrar en primer lugar que la $E[X] = 0$, para ello, procedemos como normalmente:
	
	\[
		E[X] = \int_{-\infty}^{\infty} x f(x) dx = \int_{-\infty}^{0} x f(x) dx + \int_{0}^{\infty} x f(x) dx 
	\]
	
	ahora, con un cambio de variable en la primera integral
	
	\[
		- \int_{\infty}^{0} (-t) f(-t) dt + \int_{0}^{\infty} x f(x) dx  = \int_{\infty}^{0} t f(-t) dt + \int_{0}^{\infty} x f(x) dx = 
		- \int_{0}^{\infty} t f(-t) dt + \int_{0}^{\infty} x f(x) dx 
	\]
	
	nombramos ahora t=x obteniendo
	
	\[
	- \int_{0}^{\infty} x f(-x) dt + \int_{0}^{\infty} x f(x) dx 
	\]
	
	Utilizando ahora que la función de densidad de la distribución T-Student es esférica (solo depende de x en función de $x^t x$) obtenemos que 
	\[
		- \int_{0}^{\infty} x f(x) dt + \int_{0}^{\infty} x f(x) dx = 0
	\]
	
	Notar que para que obtengamos una indeterminación del tipo $\infty - \infty$ necesitamos que las integrales sea finitas, pero lo son.
	
		
	
	\subsection{Versiones elípticas de las densidades uniformes en la hiperesfera y t-student}
	
	\textbf{EJERCICIOS:}
	\begin{itemize}
		\item Ejercicio 22:  Sea \textbf{U} un vector p-dimensional distribuido de forma uniforme en el interior y borde de la hiperesfera de dimensión \textit{p} y racio $r>0.$ Consideremos $\mu$ un vector de $\mathbb{R}^p$ y $V_{pxp}$ una matriz definida positiva descompuesta en la forma $V=CC^t$. Calcular la densidad del vector aleatorio $X=\mu+CU$.
		
		
		
		\item Ejercicio 23: Calcular $E[X]$ y $Cov[X]$ para la distribución uniforme en el elipsoide $E^p_r$.
		
		\textit{Solución:}
		
		Como $X = \mu + CU$, donde U es un vector p-dimensional siguiendo una distribución esférica, hemos demostrado al principio del trabajo que
		
		\[
			E[X] = E[\mu + CU] = E[\mu] + CE[\mu] = E[\mu] = \mu
		\]
		
		\[
			Cov[X] = C Cov[U] C^t = C \frac{r^2}{p+2}I_p C^2 = \frac{r^2}{p+2} C C^t =  \frac{r^2}{p+2} V
 		\]
		
		\item Ejercicio 24: Sea \textbf{U} un vector p-dimensional distribuido según una t de Studen multivariante esférica. Consideremos $\mu$ un vector de $\mathbb{R}^p$ y $V_{pxp}$ una matriz definida positiva descompuesta en la forma $V=CC^t$. Calcular la densidad del vector aleatorio $X=\mu+CU$. 
		
		\item Ejercicio 25: Calcular $E[X]$ y $Cov[X]$ para la distribución anterior.
		
		De forma análoga al ejercicio 23 obtenemos:
		
		\[
			E[X] = E[\mu + CU] = E[\mu] + CE[\mu] = E[\mu] = \mu
		\]
		
		\[
			Cov[X] = C Cov[U] C^t = C \frac{n}{n-2} C^t = \frac{n}{n-2} C C^t = \frac{n}{n-2}  V 
		\]
		
	\end{itemize}
	
\end{document}